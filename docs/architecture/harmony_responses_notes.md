# Harmony / Responses протокол для LLM

## Назначение и область применения
Harmony — это формат представления диалогов, который OpenAI использует в линейке моделей gpt-oss и совместим с Responses API. Протокол задаёт единое кодирование ролей, каналов и дополнительных метаданных сообщений, чтобы модель могла различать системные инструкции, разработческие указания, пользовательские запросы, поток рассуждений и вызовы инструментов. В отличие от классических Chat Completions, Harmony требует строгого следования структуре и зарезервированным токенам (`<|start|>`, `<|channel|>`, `<|message|>`, `<|end|>` и др.), а также разделяет команды для инструментов и пользовательский вывод.

## Базовые сущности
- **Роли**: `system`, `developer`, `user`, `assistant`, `tool`. Иерархия инструкций совпадает с порядком перечисления (system > developer > user > assistant > tool).
- **Каналы ассистента**:
  - `analysis` — поток внутреннего рассуждения (CoT), не предназначен для пользователя.
  - `commentary` — сообщения о планируемых действиях, вызовы инструментов, служебная информация.
  - `final` — пользовательский ответ.
- **Спецтокены**: `<|start|>` (200006), `<|channel|>` (200005), `<|message|>` (200008), `<|constrain|>` (200003), `<|end|>` (200007), `<|return|>` (200002), `<|call|>` (200012). Они используются при токенизации в словаре `o200k_harmony`.

## Структура сообщения
Каждое сообщение кодируется как `<|start|>{header}<|message|>{content}<|end|>`, где в заголовке указываются роль, канал, получатель (для инструментов) и тип контента. Системные и разработческие сообщения обычно не задают канал явно. Сообщения ассистента могут завершаться `<|return|>` (нормальное окончание генерации) или `<|call|>` (запрос вызова инструмента); перед сохранением в историю завершающий токен заменяют на `<|end|>`.

## Системное и разработческое сообщения
- **System**: фиксирует идентичность модели («You are ChatGPT…»), knowledge cutoff, текущую дату, уровень рассуждений (`Reasoning: high|medium|low`), список допустимых каналов и встроенных инструментов (browser, python и т. п.). Если доступны функции, здесь же помечается, что вызовы должны идти в `commentary`.
- **Developer**: содержит инструкции «системного промпта» и декларацию инструментов/форматов. Определение инструментов выполняется в псевдотипизации TypeScript внутри пространства имён `functions`, с комментариями для описаний и JSON Schema для структурированных ответов.

## История диалога
При формировании промпта Conversation состоит из последовательности Harmony-сообщений: системное, разработческое, затем попеременно `user` и `assistant`. Сообщения `assistant` могут включать CoT в `analysis`, затем финальный ответ или вызов инструмента. Ответы инструментов кодируются как сообщения `tool` c автором `functions.<name>` и каналом `commentary`. При повторном запросе в историю передают финальные сообщения ассистента и все tool-ответы; цепочку рассуждений сохраняют только если взаимодействие завершилось вызовом инструмента.

## Потоковая передача
Responses API возвращает поток событий: `response.stream.delta` (части контента), `response.stream.error`, `response.completed`, `response.output_text.delta`, `response.output_tool_call.delta` и т. д. Для Harmony стоит использовать `StreamableParser` из `openai_harmony`, который отслеживает текущий канал, тип контента, получателя и собирает финальные сообщения без потери юникодных последовательностей. Поток завершается событием `<|return|>` или `<|call|>`.

## Вызовы инструментов
Ассистент формирует сообщение с каналом `commentary`, указывает получателя `to=functions.<имя>` и при необходимости добавляет `<|constrain|>json` для типа аргументов. После выполнения инструмента приложение добавляет сообщение `tool` (`<|start|>functions.<имя> to=assistant<|channel|>commentary<|message|>{output}<|end|>`). В следующем проходе истории нужно включать и CoT, и tool-ответ, чтобы модель могла продолжить рассуждения.

## Практические советы по интеграции
1. **Рендеринг**: используйте `openai_harmony.Conversation` и `load_harmony_encoding`, чтобы формировать токены. При отсутствии доступа к библиотеке допустимо реализовать минимальный рендерер, но важно соблюдать формат спецтокенов.
2. **Парсинг**: обрабатывайте сообщения построчно через `StreamableParser`. Для неблокирующего вывода в Responses API доступен `responses.stream`, который передаёт те же события.
3. **Совместимость**: проверьте, поддерживает ли ваш провайдер Harmony (OpenRouter, собственный inference). Если нет, переключитесь на сервис, который умеет Responses/Harmony, и ведите сессии в едином формате.
4. **Инструменты**: перед вызовом `responses.create` приведите определения MCP-функций к плоскому виду (`type/name/parameters` без вложенного блока `function`). Это делает `convert_tools_for_harmony`, благодаря чему SDK не требует `openai.pydantic_function_tool()`.
5. **Тестирование**: пишите интеграционные тесты, симулирующие потоковые события и проверяющие разбор CoT, tool-call и финального сообщения. Для регресса удобно иметь заранее сохранённые последовательности токенов.

## Дополнительные материалы
- Репозиторий `openai_harmony`: содержит рендерер, парсер и определения токенов.
- Документация Responses API: описывает структуру событий `responses.create` и `responses.stream`.
- Примеры промптов: стоит хранить локально (например, в `tests/fixtures`) для отладки и обучения новых разработчиков.
