# Анализ технического лога агента — 7 октября 2025

## Настройка эксперимента
- Загрузил ключ OpenRouter (`export OPEN_ROUTER=…`) и выполнил интеграционный тест `pytest --suite real-llm tests/integration/test_llm_openrouter_integration.py::test_openrouter_updates_selected_requirement_translations -q`, чтобы убедиться, что реальный бэкенд работает.
- Запустил локального агента с реальным `LLMClient` и заглушкой MCP, возвращающей ответы на `get_requirement` и `update_requirement_field`. Скрипт из корня репозитория сохраняет итог в `tmp/agent_result.json` и формирует человеческий и технический журналы (`tmp/agent_plain.txt`, `tmp/agent_log.txt`).
- Все вызовы выполнялись в контейнере `python3` без дополнительных зависимостей, задержка на один прогон разговора ~20 с.

## Наблюдения
### Последовательность вызовов инструментов
Из журнала видно, что агент сделал восемь последовательных вызовов `update_requirement_field` — по два на каждое требование DEMO6–DEMO9 (сначала заголовок, затем формулировка). Пример двух первых записей, которые повторяются для остальных требований:

```json
{
  "tool_name": "update_requirement_field",
  "tool_arguments": {"rid": "DEMO6", "field": "title", "value": "Демонстрация должна содержать раздел CLI"},
  "agent_status": "completed"
}
{
  "tool_name": "update_requirement_field",
  "tool_arguments": {"rid": "DEMO6", "field": "statement", "value": "Демонстрация должна содержать раздел CLI, показывающий…"},
  "agent_status": "completed"
}
```

Все оставшиеся вызовы повторяют тот же формат, меняются только `rid` и `value` (DEMO7–DEMO9).【F:docs/investigations/2025-10-07-agent-transcript-log.md†L13-L26】

### Массовое дублирование системного промпта
В выгруженном техническом логе каждый блок `LLM request` содержит полный системный промпт, объединённый с рабочим контекстом. Обрезок из лога иллюстрирует проблему: первая запись оставляет исходный текст, но все последующие повторяют его дословно без замены на плейсхолдер `<system prompt repeated – omitted>`. Для одного шага разговоры выглядят так:

```text
[07 Oct 2025 21:07:41] LLM request:
    {
      "messages": [
        {
          "content": "Analyse the user's intent, the workspace context, and the available MCP tools before responding. …",
          "role": "system"
        },
        {
          "content": "Переведи выделенные требования на русский…",
          "role": "user"
        },
        {
          "content": "LLM response did not include a tool call or message (type: ToolValidationError)",
          "role": "assistant"
        },
        …
```

Этот фрагмент и похожие блоки встречаются 34 раза подряд — по числу сохранённых снапшотов `llm_requests` и `llm_requests.sequence`. Ни один из них не заменён на плейсхолдер.【F:docs/investigations/2025-10-07-agent-transcript-log.md†L21-L37】

### Дополнительный шум в диагностике
В диагностической секции фиксируются синтетические сообщения `invalid_tool_call` с ошибкой `ToolValidationError`, хотя агент сразу продолжает работу и завершает сценарий успешно. Эти блоки появляются из-за промежуточного шага проверки, когда LLM не вернул инструмент. Для копирующегося лога это создаёт ложное впечатление о критической ошибке: в истории видно, что после каждого такого блока всё равно следуют успешные вызовы `update_requirement_field` с нужными аргументами.【F:docs/investigations/2025-10-07-agent-transcript-log.md†L34-L37】【F:docs/investigations/2025-10-07-agent-transcript-log.md†L39-L46】

## Почему тесты не заметили проблему
- Юнит-тест `test_transcript_log_replaces_repeated_system_prompt` проверяет случай, когда системный промпт записан «как есть» в диагностике без добавленного контекста. В тестовых данных системное сообщение равно `SYSTEM_PROMPT`, поэтому алгоритм замены срабатывает, а сценарий «промпт + контекст» не покрывается.【F:tests/unit/test_agent_chat_log_export.py†L86-L106】
- Интеграционный тест `tests/integration/test_llm_openrouter_transcript_logs.py` работает с чисто пользовательским системным сообщением (контекст требований), не проходя через `SYSTEM_PROMPT` из `LLMRequestBuilder`. Следовательно, и там повторение не появляется.【F:tests/integration/test_llm_openrouter_transcript_logs.py†L80-L118】

## Рекомендации
1. **Расширить фильтрацию системного промпта.** В `_strip_repeated_system_prompt` стоит распознавать случаи, когда текст начинается с `SYSTEM_PROMPT`, даже если далее добавлен рабочий контекст. Можно отделять промпт от контекста по двойному переводу строки и заменять только первую часть на плейсхолдер, сохраняя бизнесовую часть сообщения.
2. **Добавить интеграционный тест.** Нужен сценарий, в котором `llm_requests` содержит объединённый системный промпт (значение `SYSTEM_PROMPT`) и контекст — например, реплика из `LocalAgent` после обогащения `context_messages`.
3. **Убрать синтетические `invalid_tool_call`.** Промежуточные `ToolValidationError` не несут пользы в итоговом журнале: агент сам переспрашивает LLM и завершает шаг успешно. Вместо искусственного "вызова инструмента" достаточно текста из защитного сообщения ассистента.

## Трудности и помехи
- Переменная окружения `OPEN_ROUTER` в `.env` не была экспортирована, и первый запуск скрипта завершился ошибкой, пришлось вручную делать `export`. Это легко забыть при повторном открытии сессии.
- Встроенный лимит терминала (4096 байт) обрезает длинные строки из JSON; приходилось использовать `cut` и небольшие Python-скрипты, чтобы вытащить нужные фрагменты лога.
- Реальный вызов LLM на восемь инструментов занимает ~20 с и нельзя ускорить без подмены модели.

## План дальнейших работ
- Реализовать расширенную фильтрацию системного промпта и дополнить тесты новым сценарием.
- Продумать, как представить в логе промежуточные ошибки `invalid_tool_call`, чтобы не пугать пользователей при успешном завершении шага.
- Обновить документацию после внедрения исправлений, чтобы описать финальное поведение лога.

## Состояние после исправления 2025-10-07
- Повторные системные промпты с префиксом (контекстом) теперь корректно схлопываются до плейсхолдера `<system prompt repeated – omitted>` в экспортируемом логе и в диагностических разделах, поэтому блоки `LLM request` перестали раздуваться.
- Синтетические записи `invalid_tool_call` полностью убраны: агент больше не формирует фиктивные tool call при срабатывании валидационного гарда. В журнал попадает только текст защитного ответа ассистента, поэтому история больше не заполняется «ошибками», которых фактически не происходило.
- Регрессионные проверки теперь фокусируются на повторяющемся системном промпте (`test_transcript_log_replaces_repeated_system_prompt`, `test_transcript_log_replaces_prefixed_system_prompt_but_keeps_context`); шумовые `invalid_tool_call` больше не моделируются в тестах.
